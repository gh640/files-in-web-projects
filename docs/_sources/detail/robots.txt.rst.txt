``robots.txt``
==============

``robots.txt`` は、検索エンジンなどのボットに対して、サイトのクロール方法についてのリクエストを伝えるためのファイルです。

``User-agent`` 、 ``Disallow`` 、 ``Crawl-delay`` 、 ``Sitemap`` といった定型のマークを使って、クロールしてはならないページや時間間隔などを指定します。
